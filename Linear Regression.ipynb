{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "\n",
    "    def __init__(self, lr = 0.01, epochs = 1000, tol = 1e-12, batch_size = 100_000, seed = np.random.seed(42)) -> None:\n",
    "        \n",
    "        if lr <= 0:\n",
    "            raise ValueError(\"learning rate must be positive\")\n",
    "        \n",
    "        if epochs <= 0:\n",
    "            raise ValueError(\"epoch must be positive\")\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.epochs = epochs\n",
    "        self.loss = np.zeros(shape = (self.epochs, ))\n",
    "        self.seed = seed\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def batch_generator(self, X, y):\n",
    "\n",
    "        num_samples, _ = X.shape\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for start in np.arange(0, num_samples, self.batch_size):\n",
    "\n",
    "            end = min(start + self.batch_size, num_samples)\n",
    "            yield X[start : end], y[start : end]\n",
    "        \n",
    "\n",
    "    def fit(self, X, y) -> None:\n",
    "\n",
    "        self.m, self.n = X.shape\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "        if self.y.ndim == 1:\n",
    "\n",
    "            self.weights = np.random.uniform(-0.5, 0.5, size = (self.n, ))\n",
    "            self.bias = np.random.uniform(-0.5, 0.5)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            self.weights = np.random.uniform(-0.5, 0.5, size = (self.n, 1))\n",
    "            self.bias = np.random.uniform(-0.5, 0.5)\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            total_loss = 0\n",
    "            \n",
    "\n",
    "            for x_batch, y_batch in self.batch_generator(self.x, self.y):\n",
    "\n",
    "\n",
    "                pred = self.predict(x_batch)\n",
    "                batch_loss = np.mean(np.square(y_batch - pred))\n",
    "                total_loss += batch_loss\n",
    "\n",
    "                self.weights -= self.lr * (-2 / self.batch_size) * np.dot(x_batch.T, y_batch - pred)\n",
    "                self.bias -= self.lr * (-2 / self.batch_size) * np.sum(y_batch - pred)\n",
    "\n",
    "            self.loss[epoch] = total_loss / (self.m / self.batch_size)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"epoch {epoch}/{self.epochs} -- loss {self.loss[epoch]:.2f}\")\n",
    "\n",
    "            if epoch >= 1 and np.abs(self.loss[epoch] - self.loss[epoch - 1]) < self.tol:\n",
    "\n",
    "                break\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
